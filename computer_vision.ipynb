{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "computer-vision",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOpnAMC1Hmkjp2yN8IEM8gc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NingJingwen/Computer-Vision/blob/main/computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6US2QXE1VQf"
      },
      "source": [
        "Image classifier with custom model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXyHs5nGAhLO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eOKSUvW_rnQ"
      },
      "source": [
        "import os, warnings\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory \n",
        "\n",
        "# Reproducability\n",
        "def set_seed(seed=31415):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "set_seed()\n",
        "\n",
        "# Set Matplotlib defaults\n",
        "plt.rc('figure', autolayout=True)\n",
        "plt.rc('axes', labelweight='bold', labelsize='large',\n",
        "       titleweight='bold', titlesize=18, titlepad=10)\n",
        "plt.rc('image', cmap='magma')\n",
        "warnings.filterwarnings(\"ignore\") # to clean up output cells\n",
        "\n",
        "# Load training and validation sets\n",
        "ds_train_ = image_dataset_from_directory(\n",
        "    'drive/MyDrive/car-truck-bumper/train',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    image_size=[128, 128],\n",
        "    interpolation='nearest',\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        " )\n",
        "ds_valid_ = image_dataset_from_directory(\n",
        "    'drive/MyDrive/car-truck-bumper/valid',\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    image_size=[128, 128],\n",
        "    interpolation='nearest',\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEwsV8_1Pcan"
      },
      "source": [
        "# Data Pipeline\n",
        "def convert_to_float(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "ds_train = (\n",
        "    ds_train_\n",
        "    .map(convert_to_float)\n",
        "    .cache()\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")\n",
        "ds_valid = (\n",
        "    ds_valid_\n",
        "    .map(convert_to_float)\n",
        "    .cache()\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgMceur6JRGV"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.layers.experimental.preprocessing as preprocessing\n",
        "\n",
        "# new-made model\n",
        "def create_model():\n",
        "    model = keras.Sequential([\n",
        "\n",
        "    # First Convolutional Block\n",
        "    layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding='same',\n",
        "                  # give the input dimensions in the first layer\n",
        "                  # [height, width, color channels(RGB)]\n",
        "                  input_shape=[128, 128, 3]),\n",
        "    layers.MaxPool2D(),\n",
        "\n",
        "    # Second Convolutional Block\n",
        "    layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n",
        "    layers.MaxPool2D(),\n",
        "\n",
        "    # Third Convolutional Block\n",
        "    layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n",
        "    layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n",
        "    layers.MaxPool2D(),\n",
        "\n",
        "    # Classifier Head\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(units=6, activation=\"relu\"),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(units=3, activation=\"sigmoid\"),\n",
        "    ])\n",
        "    return (model)\n",
        "\n",
        "def compile_model(model):\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n",
        "        loss = 'sparse_categorical_crossentropy',\n",
        "        metrics=['sparse_categorical_accuracy'],)\n",
        "    return(model)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA4wx5wJPpw4"
      },
      "source": [
        "# import os\n",
        "\n",
        "# try:\n",
        "#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR']) \n",
        "#     print('Running on TPU ', tpu.master())\n",
        "# except ValueError:\n",
        "#     tpu = None\n",
        "\n",
        "# if tpu:\n",
        "#     tf.config.experimental_connect_to_cluster(tpu)\n",
        "#     tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "#     strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "# else:\n",
        "#     strategy = tf.distribute.get_strategy() \n",
        "\n",
        "# with strategy.scope():\n",
        "#     model = create_model()\n",
        "#     model = compile_model(model)\n",
        "model=create_model()\n",
        "model=compile_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf0Vzp66PWzy"
      },
      "source": [
        "history = model.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_valid,\n",
        "    epochs=15,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jfgv3dBZMoXB"
      },
      "source": [
        "import pandas as pd\n",
        "history_frame = pd.DataFrame(history.history)\n",
        "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
        "history_frame.loc[:, ['sparse_categorical_accuracy', 'val_sparse_categorical_accuracy']].plot();"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}